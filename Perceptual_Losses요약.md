# Perceptual_Losses 

> perceptual loss(판단손실)은 근처 픽셀과의 관계 등 좀더 현실적인 정보(?)</br>
어떤 semanic feature가 유지되기 위함임

이미지 처리에서의 예로는 디노이즈, 초해상도(해상도 복원), colorzation 이있는데, </br>
여기서 인풋은 저하된 이미지(노이즈, 저해상도 또는 그레이스케일)이고 출력은 고품질 컬러 이미지다.</br>
컴퓨터 영상처리로부터의 예시는 semantic segmentation(의미있는 분류 즉 분류를 넘어서 그 장면을 완벽히 이해하는 것), </br>
depth estimation(?) 을 포함하는데 여기서 인풋은 컬러이미지고 아웃풋은 그 장면에 대한 의미 또는 기하학적 정보를 인코딩한다. </br>
</br>
이미지 스타일 변환을 해결하기위한 하나의 접근법은 **픽셀** 당 손실함수를 사용하여 출력이미지와</br>
groud-truth images(사물이 실제 위치한 정보) 간의 차이를 피드포워드 뉴럴신경망을 지도학습(?)안에서 학습시키는 것이다. </br>
</br>
~~예를 들어 이 접근방식은 초해상도[1]에 동 외 연구진, ~~</br>
~~색채화를 위한 청 외 연구진[2], 분할을 위한 롱 외 연구진[3],~~ </br>
~~깊이와 표면 정상 예측을 위해 아이겐 외 연구진이 사용하였다[4,5].~~</br> 
</br>
이러한 접근법은 테스트 시간에 효율적이며 학습된 네트워크를 통과하는 전진패스(?)만 필요하다 </br>
그러나 이러한 방법에 사용되는 픽셀당 손실은 출력이미지와 ground-truth images간의 perceptual differences를 잘 잡지 못한다</br>
2를 보자</br>

![perceptuallosses](https://user-images.githubusercontent.com/43857226/64936736-4ff82c80-d892-11e9-93b3-506cc33c1868.JPG) </br>

style transfer(top) 그리고 x4 초해상도(bottom)에 대한 결과 style transfer의 경우 Gatys et al과 유사한 결과를 얻지만 </br>
나머지 세 경우 더 빠른 순서를 가진다(?) </br>
초해상도를 위해 지각손실을 사용한 우리의 방법은 픽셀단위로 학습된 방법보다 디테일을 더 잘 구성할 수 있다. </br>
~~ 동일한 이미지가 픽셀당 손실 측정시 매우 다를 수 있는 지각적 유사성(?) 에도 불구하고 한 픽셀씩 서로 상쇄된다.~~ </br>
최근 연구는 고품질 이미지를 생성할 수 있다는 걸 보여준다. 픽셀간 차이가 아니라 미리 훈련된 CNN에서 추출한 고차원 영상</br>
특징 표현들 간의 차이에 기초한 perceptual losses를 사용하여서 </br>
</br>

이 논문에서 두가지 이점을 결합 </br>
style transfer를 위해 피드 포워드 네트워크를 학습하지만 낮은 픽셀 정보에만 의존하는 픽셀당 손실함수를 사용하기 보다</br>
사전학습된 loss 네트워크로부터 하이레벨기능에 의존하는 perceptual loss를 사용하여 트레이닝 한다.</br>
훈련중 perceptual loss는 픽셀당 losses 보다 이미지 유사성을 강력하게 측정하면서 실시간으로 네트워크가 수행한다. </br>
