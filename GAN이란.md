# GAN
GAN이란 Generative Adversarial Network의 약자 그럴듯한 가짜를 만들어내는 모델 비지도 학습  </br>
적대적 학습 생성모델의 모적은 실제 데이터 분포와 근사한 것 Adversarial 은 경쟁시키며 발전시킨다.
생성자는 판별자의 실수를 최대한으로 유도해내는 것. 임의의 공간에서 G와 D는 각각의 솔루션 존재
모든 시스템은 오차역전파에 의해 학습된다. 
GAN은 생성자와 구분자를 경쟁적으로 학습시킨다.
생성자의 목적은 가짜데이터를 만들어 구분자를 속이는 것이며 구분자의 목적은 생성자가 만든
가짜 데이터와 진짜 데이터를 구분하는 것.</br>
인공신경망응 이전층의 출력값에 가중치나 매개변수를 곱해 합하여 다음 뉴런의 입력값으로 들어간다.
딥러닝을 학습시킨다는것은 최적의 가중치를 찾아간다는 것. </br></br>

> 지폐위조범(Generator)은 경찰을 최대한 열심히 속이려고 하고 다른 한편에서는 경찰(Discriminator)이 이렇게 </br>
위조된 지폐를 진짜와 감별하려고(Classify) 노력한다.</br>
이런 경쟁 속에서 두 그룹 모두 속이고 구별하는 서로의 능력이 발전하게 되고 </br>
결과적으로는 진짜 지폐와 위조 지폐를 구별할 수 없을 정도(구별할 확률 pd=0.5)에 이른다는 것.</br>

## 수식

![GAN수식](https://user-images.githubusercontent.com/43857226/62433664-544c0880-b770-11e9-8d44-c66a6546ee8f.png)

먼저 D가 V(D,G)를 최대화 하는 관점에서 보면 x ~ pdata(x)는 실데이터의 *확률분포* x는 그중 샘플링한 데이터 </br>
실데이터라면 log1, 즉 최대값인 0에 가깝게 나오고 가짜 데이터라면 무한으로 발산하기 때문에 
함수를 최대화 하는 방향으로 학습</br>

> 로그란 base가 10인 상용로그에서 몇제곱해야 그 값이 나오는가를 알아내는 함수 </br>
로그 3이란 10에서 몇번 제곱해야 3이 나오는가?? </br>
log3 = 0.47712125471966243729502790325512 실제로 2.99999999에 가까운 값이 출력

생성자부분인 오른쪾은 함수를 최소화 해야 한다. z ~ pz(z)는 보통 정규분포로 사용하는 임의의 노이즈 분포
z는 노이즈분포에서 샘플링한 임의의 코드 그리고 이 입력을 생성자 G에 넣어 만든 데이터를 판별자가 속아 넘어가서
진짜로 판별되면 log(1-D(G(z))) 이기때문에 D(G(z))이며 무한으로 발산하고 판별자를 속이지 못하면 D(G(z))는 
0이기 때문에 log(1-D(G(z)))는 0에 가까운 최대값이 나오게 된다. 따라서 G는 최소화 하는 방향으로 학습 즉
GAN은
> V(D,G)에 있어 G는 이를 최소화하는 방향 D는 최대화 하는 방향으로 가게 하는 것
V(D,G)는 minmax하는 과정이 G가 만드는 확률분포와 오리지날 데이터의 확률분포의 차이를 줄여나가는 것.
확률분포의 차이를 계산하기 위해 JSD를 사용 

![JSD](https://user-images.githubusercontent.com/43857226/62434828-f1a93b80-b774-11e9-864c-78be84e59aec.png)

JSD는 원래 확류분포와 생성자의 확률분포를 KLD한 값과 G의 확률분포와 원래 확률분포G의 확률분포를 KLD한 값의
평균을 구해 두 확률분포간의 차이를 구하는 것.
이와 같은 발산을 통해 원래 확분이랑 생성자의 확분이 0이 되면 차이가 없다는 것으로 학습이 완료되었다는 것.

생성자는 랜덤벡터 'z'를 입력으로 받아 가짜이미지를 출력하는 함수 
'z'는 단순하게 균등분포나 정규분포에서 무작위로 추출된 값.생성자는 단순한 분포를 복잡한 분포로 맵핑
'z'벡터가 존재하는 공간을 잠재공간이라고 부른다. 
구분자는 이미지를 입력받고 그 이미지가 진짜 가짜일 확률 0과1 사이 소수를 하나 출력
4개의 선형 레이어를 쌓고 레이어 마다 활성함수로 렐루를 대입
드랍아웃을 통해 학습시 무작위로 절반의 뉴런을 날려버린다. 이를통해 과적합 방지하며
구분자가 생성자보다 지나치게 빨리 학습하는 것을 방지</br>

생성자와 구분자를 만들었으면 학습해야 한다. 학습하기 위해선 모델을 평가할 수 있어야 한다.
구분자의 출력값은 이미지가 진짜일 확률 이를 위해 바이너리 크로스 엔트로피와 손실함수를 사용한다.
구분자의 출력값이 정답에 가까우면 낮아지고 멀면 높아진다. 이 손실함수의 값을 낮추는 것이 모델학습의 목표
***구분자의 출력값은 두가지 합으로 이루어진다. 진짜 이미지를 입력했을 때 출력값과 1의 차이 ***

가짜 이미지를 입력했을 때 출력값과 0의 차이 두 경우의 합이 구분자의 손실함수이다. </br>
생성자는 가짜이미지를 입력해도 1의 가까운 값이 나와야 한다. 이 값이 1과의 차이가 생성자의 손실함수가 되고
이를 최소화 하는 것이 목표이다.
